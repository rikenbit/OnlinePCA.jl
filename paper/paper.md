---
title: 'OnlinePCA.jl: A Julia Package for Out-of-core and Sparse Principal Component Analysis'
tags:
  - Julia
  - Principal Component Analysis
  - Out-of-Core
  - Sparse
  - dimensionality reduction
authors:
  - name: Koki Tsuyuzaki
    orcid: 0000-0003-3797-2148
    affiliation: "1, 2"
affiliations:
 - name: Department of Artificial Intelligence Medicine, Graduate School of Medicine, Chiba University, Japan
   index: 1
 - name: Laboratory for Bioinformatics Research, RIKEN Center for Biosystems Dynamics Research, Japan
   index: 2
date: 1 July 2025
bibliography: paper.bib
---

# Summary

Principal Component Analysis (PCA) is a widely used dimensionality reduction technique for identifying a small number of components that capture the maximum variance in high-dimensional data [@review1; @review2]. PCA has been applied across various fields of data science, including face recognition [@eigenface], animal behavior analysis [@eigenworm], omics studies [@review1; @review2; @onlinepcajl], population genetics [@genetics; @pcaone], and molecular dynamics simulations [@md].

Despite its broad applicability, PCA becomes computationally prohibitive for large data matrices, making it difficult to apply in practice. In particular, recent advances in single-cell omics have led to datasets with millions of cells, for which standard PCA implementations often fail to scale. To meet this requirement, I originally developed \texttt{OnlinePCA.jl}, which is a Julia package to perform some PCA algorithms (\url{https://github.com/rikenbit/OnlinePCA.jl}).

# Statement of need

PCA is a workhorse algorithm for most data science tasks. However, as the size of the data matrix increases, it often becomes too large to fit into memory. In such cases, an out-of-core (OOC) implementation — where only subsets of data stored on disk are loaded into memory for computation — is desirable. Additionally, representing the data in a sparse matrix format, where only non-zero values and their coordinates are stored, is computationally advantageous [@onlinepcajl]. Therefore, a PCA implementation that supports both OOC computation and sparse data handling is highly desirable.

## New features since version 0.3.0

\texttt{OnlinePCA.jl} has been provided some OOC PCA functions such as \texttt{oja}, \texttt{ccipca}, \texttt{gd}, \texttt{rsgd}, \texttt{svrg}, \texttt{rsvrg}, \texttt{orthiter}, \texttt{arnoldi}, \texttt{lanczos}, \texttt{halko}, \texttt{algorithm971}, \texttt{rbkiter}, \texttt{singlepass}, and \texttt{singlepass2} and an OOC/Sparse PCA function (\texttt{tenxpca}) only for a sparse matrix in HDF5 files generated by 10X Cell Ranger (10X-HDF5) [@onlinepcajl]. These implementations were designed to take "CSV" files containing "short and fat" matrices—that is, matrices with relatively few rows (samples) and a large number of columns (features)—as typically seen in large-scale single-cell datasets.

Since version 0.3.0, the following new features have been introduced:

- *Support for Matrix Market and Binary COO formats*: Many large-scale datasets are represented as extremely sparse matrices, where only a small fraction of entries are non-zero. One widely used format for such sparse data is the Matrix Market (MM) format, which stores non-zero values along with their corresponding (x, y) coordinates in three columns. To handle this format, we implemented the \texttt{mm2bin} function for binary conversion and extended the \texttt{sumr} function with a \texttt{sparse\_mode} option to extract summary statistics efficiently. Furthermore, we introduced a new format called Binary COO (BinCOO), which assumes all non-zero values are 1 and stores only the (x, y) coordinates. The corresponding function \texttt{bincoo2bin} has also been newly implemented.
- \texttt{sparse\_rsvd}: In earlier versions of \texttt{OnlinePCA.jl} [@onlinepcajl], the \texttt{tenxpca} function was implemented specifically for performing PCA on a sparse matrix in 10X-HDF5. The \texttt{sparse\_rsvd} function generalizes this approach to a sparse matrix as Matrix Market (MM) format. It assumes as input a binary-converted sparse matrix generated by \texttt{mm2bin}, along with summary statistics computed using sumr with the \texttt{sparse\_mode} option.
- \texttt{exact\_ooc\_pca}: The \texttt{exact\_ooc\_pca} function is designed for "tall and thin" matrices, where it performs OOC computation of the covariance matrix followed by eigendecomposition. Unlike other functions, it does not require precomputed summary statistics via \texttt{sumr} and instead directly accepts a binary-converted data matrix as input. Supported input formats include CSV, Matrix Market (MM), and BinCOO. The eigendecomposition is performed using Julia’s standard \texttt{eigen} function, and since this method does not rely on approximated solutions such as IRLBA or Randomized SVD, the resulting principal components are mathematically equivalent to those obtained by running offline PCA with the full data loaded into memory [@onlinepcajl].
- Adjustable chunk size: The \texttt{sparse\_rsvd} and \texttt{exact\_ooc\_pca} functions include a \texttt{chunksize} option, which allows users to control the amount of data loaded into memory at once. This feature is based on our previous benchmarking with large-scale single-cell datasets [@onlinepcajl], where we found that processing data in moderately sized chunks, rather than row by row, significantly improved computational efficiency.

![Overview of workflow in OnlinePCA.jl since v0.3.0.\label{fig:pca}](figure.png){ width=100% }

# Example

PCA can be easily reproduced on any machine where Julia is pre-installed by using the following commands in the Julia REPL window:

## Installation

First, install \texttt{OnlinePCA.jl} from the official Julia package registry or directly from GitHub:

```julia
# Install OnlinePCA.jl from Julia General
julia> Pkg.add("OnlinePCA")

# or GitHub for the latest version
julia> Pkg.add(url="https://github.com/rikenbit/OnlinePCA.jl.git")
```

## Preprocess of CSV

Then, write a synthetic data as a CSV file, convert it to a compressed binary format using Zstandard, and prepare summary statistics for PCA. MM format is also supported for sparse matrices.

```julia
using OnlinePCA
using OnlinePCA: write_csv
using Distributions
using DelimitedFiles
using SparseArrays
using MatrixMarket

# CSV
tmp = mktempdir()
data = Int64.(ceil.(rand(NegativeBinomial(1, 0.5), 300, 99)))
data[1:50, 1:33] .= 100*data[1:50, 1:33]
data[51:100, 34:66] .= 100*data[51:100, 34:66]
data[101:150, 67:99] .= 100*data[101:150, 67:99]
write_csv(joinpath(tmp, "Data.csv"), data)

# Binarization (Zstandard)
csv2bin(csvfile=joinpath(tmp, "Data.csv"),
    binfile=joinpath(tmp, "Data.zst"))

# Matrix Market (MM)
mmwrite(joinpath(tmp, "Data.mtx"), sparse(data))

# Binarization (Zstandard)
csv2bin(csvfile=joinpath(tmp, "Data.csv"),
    binfile=joinpath(tmp, "Data.zst"))

# Summary of data for CSV/Dense Matrix
dense_path = mktempdir()
sumr(binfile=joinpath(tmp, "Data.zst"), outdir=dense_path)
```

## Setting for plot

Define a helper function to visualize the results of PCA using the \texttt{PlotlyJS.jl} package. It generates two subplots: PC1 vs PC2 and PC2 vs PC3, with color-coded groups.

```julia
using DataFrames
using PlotlyJS

function subplots(respca, group)
  # data frame
  data_left = DataFrame(pc1=respca[:,1], pc2=respca[:,2], group=group)
  data_right = DataFrame(pc2=respca[:,2], pc3=respca[:,3], group=group)
  # plot
  p_left = Plot(data_left, x=:pc1, y=:pc2, mode="markers",
      marker_size=10, group=:group)
  p_right = Plot(data_right, x=:pc2, y=:pc3, mode="markers",
      marker_size=10,
  group=:group, showlegend=false)
  p_left.data[1]["marker_color"] = "red"
  p_left.data[2]["marker_color"] = "blue"
  p_left.data[3]["marker_color"] = "green"
  p_right.data[1]["marker_color"] = "red"
  p_right.data[2]["marker_color"] = "blue"
  p_right.data[3]["marker_color"] = "green"
  p_left.data[1]["name"] = "group1"
  p_left.data[2]["name"] = "group2"
  p_left.data[3]["name"] = "group3"
  p_left.layout["title"] = "PC1 vs PC2"
  p_right.layout["title"] = "PC2 vs PC3"
  p_left.layout["xaxis_title"] = "pc1"
  p_left.layout["yaxis_title"] = "pc2"
  p_right.layout["xaxis_title"] = "pc2"
  p_right.layout["yaxis_title"] = "pc3"
  plot([p_left p_right])
end

group=vcat(repeat(["group1"],inner=33), repeat(["group2"],inner=33),
    repeat(["group3"],inner=33))
```

## PCA using Halko’s method on CSV input

This example shows how to perform PCA using Halko's randomized SVD method on dense CSV input. The result is visualized in the PC1–PC3 space.

```julia
out_halko = halko(input=joinpath(tmp, "Data.zst"), dim=3,
    rowmeanlist=joinpath(dense_path, "Feature_LogMeans.csv"))

subplots(out_halko[1], group)
```

![Output of halko against CSV format.\label{fig:pca1}](halko.png){ width=100% }

## Preprocessing sparse data in Matrix Market format

The following code converts a sparse matrix in MM format into a binary compressed format and computes summary statistics for PCA.

```julia
# Sparsification + Binarization (Zstandard + MM format)
mm2bin(mmfile=joinpath(tmp, "Data.mtx"),
    binfile=joinpath(tmp, "Data.mtx.zst"))

sparse_path = mktempdir()
sumr(binfile=joinpath(tmp, "Data.mtx.zst"),
    outdir=sparse_path, mode="sparse_mm")
```

## PCA using \texttt{sparse\_rsvd} on Matrix Market input

This example performs PCA using the \texttt{sparse\_rsvd} method, designed for sparse input data in MM format. The top 3 components are visualized.

```julia
out_sparse_rsvd = sparse_rsvd(
  input=joinpath(tmp, "Data.mtx.zst"),
  scale="ftt",
  rowmeanlist=joinpath(sparse_path, "Feature_FTTMeans.csv"),
  dim=3, chunksize=100)

subplots(out_sparse_rsvd[1], group)
```

![Output of sparse_rsvd against MM format.\label{fig:pca2}](sparse_rsvd.png){ width=100% }











## Preparing another sparse matrix for \texttt{exact\_ooc\_pca}

This example generates a BinCOO format data to simulate "tall and thin" matrix and compresses it by \texttt{bincoo2bin} for use with \texttt{exact\_ooc\_pca}.

```julia
# Binary COO (BinCOO)
tmp2 = mktempdir()
data2 = Int64.(ceil.(rand(Binomial(1, 0.2), 99, 33)))
data2[1:33, 1:11] .= 1
data2[34:66, 12:22] .= 1
data2[67:99, 23:33] .= 1

bincoofile = joinpath(tmp2, "Data2.bincoo")
open(bincoofile, "w") do io
    for i in 1:size(data2, 1)
        for j in 1:size(data2, 2)
            if data2[i, j] != 0
                println(io, "$i $j")
            end
        end
    end
end

# Binarziation (BinCOO + Zstandard)
bincoo2bin(bincoofile=bincoofile, binfile=joinpath(tmp2, "Data2.bincoo.zst"))
```

## PCA using \texttt{exact\_ooc\_pca} on BinCOO input

Here, we apply \texttt{exact\_ooc\_pca}, which computes the full covariance matrix in a OOC manner and performs eigendecomposition.

```julia
# Sparse-mode (BinCOO)
out_exact_ooc_pca_sparse_bincoo = exact_ooc_pca(
  input=joinpath(tmp2, "Data2.bincoo.zst"),
  scale="raw", dim=3, chunksize=10, mode="sparse_bincoo")

subplots(out_exact_ooc_pca_sparse_bincoo[3], group)
```

![Output of exact_ooc_pca against BinCOO format.\label{fig:pca3}](exact_ooc_pca_sparse_bincoo.png){ width=100% }

For more details, see the README.md of \texttt{OnlinePCA.jl} at \url{https://github.com/rikenbit/OnlinePCA.jl}.

# Related work

There are various implementations of PCA and some of them are OOC-type or sparse-type [@sklearn; @dask; @pcaone] but \texttt{OnlinePCA.jl} is the only tool that supports both OOC computation and sparse data formats (e.g., 10X-HDF5, MM, BinCOO).

| Function Name | Language | OOC | Sparse Format |
|:------ | :----: | :----: | :----: |
| \texttt{prcomp/princomp} | R | No | - |
| \texttt{sklearn.decomposition.PCA} | Python | No | - |
| \texttt{MultivariateStats.PCA} | Julia | No | - |
| \texttt{oocRPCA::oocPCA\_CSV} | R | Yes | - |
| \texttt{sklearn.decomposition.IncrementalPCA} | Python | Yes | - |
| \texttt{dask\_ml.decomposition.PCA} | Python | Yes | - |
| \texttt{PCAone} | R/C++ | Yes | - |
| \texttt{irlba::prcomp\_irlba} | R | No | dgCMatrix |
| \texttt{sklearn.decomposition.TruncatedSVD} | Python | No | scipy.sparse |
| \texttt{tenxpca} | Julia | Yes | 10X-HDF5 |
| \texttt{sparse\_rsvd} | Julia | Yes | MM |
| \texttt{exact\_ooc\_pca} | Julia | Yes | CSV/MM/BinCOO |

For a more comprehensive comparison, see the Figure 2 in [@onlinepcajl].

# References
